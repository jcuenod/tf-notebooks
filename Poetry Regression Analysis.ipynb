{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 3.1.1\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "114 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.02s B book                 from /home/jcuenod/Programming/tf-github/bhsa/tf/2017\n",
      "   |     0.01s B chapter              from /home/jcuenod/Programming/tf-github/bhsa/tf/2017\n",
      "   |     0.02s B verse                from /home/jcuenod/Programming/tf-github/bhsa/tf/2017\n",
      "   |     0.26s T txt                  from /home/jcuenod/Programming/tf-github/bhsa/tf/2017\n",
      "   |     0.05s B kind                 from /home/jcuenod/Programming/tf-github/bhsa/tf/2017\n",
      "   |     0.18s B rela                 from /home/jcuenod/Programming/tf-github/bhsa/tf/2017\n",
      "   |     0.18s B typ                  from /home/jcuenod/Programming/tf-github/bhsa/tf/2017\n",
      "   |     0.04s B domain               from /home/jcuenod/Programming/tf-github/bhsa/tf/2017\n",
      "   |     0.00s Feature overview: 108 for nodes; 5 for edges; 1 configs; 7 computed\n",
      "  5.53s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "import sys, os, collections\n",
    "from tf.fabric import Fabric\n",
    "DATABASE = '~/Programming/tf-github'\n",
    "BHSA = 'bhsa/tf/2017'\n",
    "TF = Fabric(locations=[DATABASE], modules=[BHSA], silent=False)\n",
    "\n",
    "api = TF.load('''\n",
    "    book chapter verse\n",
    "    txt kind rela typ domain\n",
    "''')\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up data points\n",
    "\n",
    "Here we set up all the data points that we will analyse (listed here mainly in order to have a handy reference).\n",
    "\n",
    "`is_Poetry` will be the dependent variable and, hopefully we will find some kind of correlation to other points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_points = {\n",
    "    \"is_Poetry\": 0,\n",
    "    \"depth\": 0,\n",
    "#     \"txt\": 0,\n",
    "    \"is_Kind_VC\": 0,\n",
    "    \"is_Kind_WP\": 0,\n",
    "    \"is_Kind_NC\": 0,\n",
    "    \"is_Rela_ReVo\": 0,\n",
    "    \"is_Rela_Coor\": 0,\n",
    "    \"is_Rela_Attr\": 0,\n",
    "    \"is_Rela_Cmpl\": 0,\n",
    "    \"is_Rela_Resu\": 0,\n",
    "    \"is_Rela_Adju\": 0,\n",
    "    \"is_Rela_Objc\": 0,\n",
    "    \"is_Rela_RgRc\": 0,\n",
    "    \"is_Rela_Subj\": 0,\n",
    "    \"is_Rela_PrAd\": 0,\n",
    "    \"is_Rela_PreC\": 0,\n",
    "    \"is_Rela_Spec\": 0,\n",
    "    \"is_Typ_AjCl\": 0,\n",
    "    \"is_Typ_CPen\": 0,\n",
    "    \"is_Typ_Defc\": 0,\n",
    "    \"is_Typ_Ellp\": 0,\n",
    "    \"is_Typ_InfA\": 0,\n",
    "    \"is_Typ_InfC\": 0,\n",
    "    \"is_Typ_MSyn\": 0,\n",
    "    \"is_Typ_NmCl\": 0,\n",
    "    \"is_Typ_Ptcp\": 0,\n",
    "    \"is_Typ_Reop\": 0,\n",
    "    \"is_Typ_Unkn\": 0,\n",
    "    \"is_Typ_Voct\": 0,\n",
    "    \"is_Typ_Way0\": 0,\n",
    "    \"is_Typ_WayX\": 0,\n",
    "    \"is_Typ_WIm0\": 0,\n",
    "    \"is_Typ_WImX\": 0,\n",
    "    \"is_Typ_WQt0\": 0,\n",
    "    \"is_Typ_WQtX\": 0,\n",
    "    \"is_Typ_WxI0\": 0,\n",
    "    \"is_Typ_WXIm\": 0,\n",
    "    \"is_Typ_WxIX\": 0,\n",
    "    \"is_Typ_WxQ0\": 0,\n",
    "    \"is_Typ_WXQt\": 0,\n",
    "    \"is_Typ_WxQX\": 0,\n",
    "    \"is_Typ_WxY0\": 0,\n",
    "    \"is_Typ_WXYq\": 0,\n",
    "    \"is_Typ_WxYX\": 0,\n",
    "    \"is_Typ_WYq0\": 0,\n",
    "    \"is_Typ_WYqX\": 0,\n",
    "    \"is_Typ_xIm0\": 0,\n",
    "    \"is_Typ_XImp\": 0,\n",
    "    \"is_Typ_xImX\": 0,\n",
    "    \"is_Typ_XPos\": 0,\n",
    "    \"is_Typ_xQt0\": 0,\n",
    "    \"is_Typ_XQtl\": 0,\n",
    "    \"is_Typ_xQtX\": 0,\n",
    "    \"is_Typ_xYq0\": 0,\n",
    "    \"is_Typ_XYqt\": 0,\n",
    "    \"is_Typ_xYqX\": 0,\n",
    "    \"is_Typ_ZIm0\": 0,\n",
    "    \"is_Typ_ZImX\": 0,\n",
    "    \"is_Typ_ZQt0\": 0,\n",
    "    \"is_Typ_ZQtX\": 0,\n",
    "    \"is_Typ_ZYq0\": 0,\n",
    "    \"is_Typ_ZYqX\": 0,\n",
    "    \"is_Domain_N\": 0,\n",
    "    \"is_Domain_Q\": 0,\n",
    "    \"is_Domain_D\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define some helper methods\n",
    "\n",
    "`inScope` just limits us to the corpus for which we have defined which sections are poetic.\n",
    "\n",
    "`isPoetry` is going to tell us whether we should define a particular node as poetic (this is based on rough guestimates eyeballing my way through an English Bible - i.e. completely unreliable at this point but good enough for a ballpark). Some things that may be worth improving here are looking at the clauses at the start of poetry because often those have wayyiqtols (or other unusual features), for example, and may significantly affect data in the bigger picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scope = [\"Genesis\", \"Exodus\", \"Leviticus\", \"Numbers\", \"Deuteronomy\", \"1_Samuel\", \"2_Samuel\", \"Psalms\", \"Proverbs\"]\n",
    "def inScope(node):\n",
    "    book, chapter, verse = T.sectionFromNode(node)\n",
    "    return book in scope\n",
    "\n",
    "def isPoetry(node):\n",
    "    book, chapter, verse = T.sectionFromNode(node)\n",
    "    if book == \"Psalms\" or book == \"Proverbs\":\n",
    "        return True\n",
    "    elif book == \"Genesis\":\n",
    "        if chapter == 49 and verse > 1 and verse < 28:\n",
    "            return True\n",
    "    elif book == \"Exodus\":\n",
    "        if chapter == 15 and verse < 19:\n",
    "            return True\n",
    "    elif book == \"Numbers\":\n",
    "        if chapter == 21 and verse in [15, 18, 27, 28, 29, 30]:\n",
    "            return True\n",
    "        if chapter == 23 and ((verse > 6 and verse < 11) or (verse > 17 and verse < 24)):\n",
    "            return True\n",
    "        if chapter == 24 and ((verse > 2 and verse < 10) or (verse > 14 and verse < 25)):\n",
    "            return True\n",
    "    elif book == \"Deuteronomy\":\n",
    "        if chapter == 28 and ((verse > 2 and verse < 7) or (verse > 15 and verse < 20)):\n",
    "            return True\n",
    "        if chapter == 32 and verse < 44:\n",
    "            return True\n",
    "        if chapter == 33:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Data Set\n",
    "\n",
    "Now we cycle through all the clauses, if they're in our scope, we add their data points (most importantly, whether or not they are poetry)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "50000\n",
      "75000\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "failures = {}\n",
    "def addFail(key):\n",
    "    if key not in failures:\n",
    "        failures[key] = 0\n",
    "    failures[key] += 1\n",
    "\n",
    "progress = 0\n",
    "data_set = []\n",
    "for c in F.otype.s('clause'):\n",
    "    progress += 1\n",
    "    if progress % 25000 == 0:\n",
    "        print(progress)\n",
    "    if inScope(c):\n",
    "        curr_data = data_points.copy()\n",
    "        curr_data[\"is_Poetry\"] = 1 if isPoetry(c) else 0\n",
    "        \n",
    "        curr_data[\"depth\"] = len(F.txt.v(c))\n",
    "#         curr_data[\"txt\"] = F.txt.v(c)\n",
    "        \n",
    "        if \"is_Rela_\" + F.rela.v(c) in curr_data:\n",
    "            curr_data[\"is_Rela_\" + F.rela.v(c)] = 1\n",
    "        else:\n",
    "            addFail(\"is_Rela_\" + F.rela.v(c))\n",
    "        if \"is_Domain_\" + F.domain.v(c) in curr_data:\n",
    "            curr_data[\"is_Domain_\" + F.domain.v(c)] = 1\n",
    "        else:\n",
    "            addFail(\"is_Domain_\" + F.domain.v(c))\n",
    "        if \"is_Typ_\" + F.typ.v(c) in curr_data:\n",
    "            curr_data[\"is_Typ_\" + F.typ.v(c)] = 1\n",
    "        else:\n",
    "            addFail(\"is_Typ_\" + F.typ.v(c))\n",
    "        if \"is_Kind_\" + F.kind.v(c) in curr_data:\n",
    "            curr_data[\"is_Kind_\" + F.kind.v(c)] = 1\n",
    "        else:\n",
    "            addFail(\"is_Kind_\" + F.kind.v(c))\n",
    "        \n",
    "        data_set.append(curr_data)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's just check that we haven't left out any values as we added them to our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is_Rela_NA': 29021, 'is_Domain_?': 1644}\n"
     ]
    }
   ],
   "source": [
    "print(failures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build DataFrame\n",
    "\n",
    "This is just a matter of shoving all those datapoints into a pandas object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38049, 65)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "pdd = DataFrame.from_records(data_set)\n",
    "\n",
    "pdd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write this data to a csv file so that we can use it without doing the crazy processing all the time in the future..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdd.to_csv(\"poetry_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Regression\n",
    "\n",
    "Let's try a first attempt at multiple regression.\n",
    "\n",
    "If you're wondering what these things mean, well so am I mostly but you can have a look here:\n",
    "\n",
    "1. For Rela: https://etcbc.github.io/bhsa/features/hebrew/2017/rela\n",
    "2. For Typ: https://etcbc.github.io/bhsa/features/hebrew/2017/typ\n",
    "3. For Domain: https://etcbc.github.io/bhsa/features/hebrew/2017/domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.73241608598e+12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('depth', -0.1603949846336849),\n",
       " ('is_Kind_VC', 1613193902255.606),\n",
       " ('is_Kind_WP', 1768328350048.6147),\n",
       " ('is_Kind_NC', 2114820553912.6621),\n",
       " ('is_Rela_ReVo', 0.33807960551732996),\n",
       " ('is_Rela_Coor', 0.1729376975301056),\n",
       " ('is_Rela_Attr', -0.16340225488908011),\n",
       " ('is_Rela_Cmpl', -0.02309672770771698),\n",
       " ('is_Rela_Resu', -0.09634129007856948),\n",
       " ('is_Rela_Adju', -0.13481735448065013),\n",
       " ('is_Rela_Objc', -0.10665372343821609),\n",
       " ('is_Rela_RgRc', -0.10514376506693368),\n",
       " ('is_Rela_Subj', 0.10189633140753315),\n",
       " ('is_Rela_PrAd', -0.21370210408573992),\n",
       " ('is_Rela_PreC', -0.067629170116258713),\n",
       " ('is_Rela_Spec', -0.02406241698109348),\n",
       " ('is_Typ_AjCl', -382404467928.60931),\n",
       " ('is_Typ_CPen', -35912264064.676376),\n",
       " ('is_Typ_Defc', 31310101344.212196),\n",
       " ('is_Typ_Ellp', -35912264064.536659),\n",
       " ('is_Typ_InfA', 119222183728.36572),\n",
       " ('is_Typ_InfC', 119222183728.41867),\n",
       " ('is_Typ_MSyn', -35912264064.622314),\n",
       " ('is_Typ_NmCl', -382404467928.65149),\n",
       " ('is_Typ_Ptcp', 119222183728.48151),\n",
       " ('is_Typ_Reop', -35912264064.637871),\n",
       " ('is_Typ_Unkn', -25102937587.589756),\n",
       " ('is_Typ_Voct', -35912264064.238846),\n",
       " ('is_Typ_Way0', 119222183728.43471),\n",
       " ('is_Typ_WayX', 119222183728.32434),\n",
       " ('is_Typ_WIm0', 119222183728.43761),\n",
       " ('is_Typ_WImX', 119222183728.10457),\n",
       " ('is_Typ_WQt0', 119222183728.12723),\n",
       " ('is_Typ_WQtX', 119222183728.13702),\n",
       " ('is_Typ_WxI0', 119222183728.57687),\n",
       " ('is_Typ_WXIm', 119222183728.27118),\n",
       " ('is_Typ_WxIX', -41917226479.071426),\n",
       " ('is_Typ_WxQ0', 119222183728.41345),\n",
       " ('is_Typ_WXQt', 119222183728.34888),\n",
       " ('is_Typ_WxQX', 119222183728.29741),\n",
       " ('is_Typ_WxY0', 119222183728.3378),\n",
       " ('is_Typ_WXYq', 119222183728.46373),\n",
       " ('is_Typ_WxYX', 119222183728.21466),\n",
       " ('is_Typ_WYq0', 119222183728.49953),\n",
       " ('is_Typ_WYqX', 119222183728.60107),\n",
       " ('is_Typ_xIm0', 119222183728.62881),\n",
       " ('is_Typ_XImp', 119222183728.27716),\n",
       " ('is_Typ_xImX', 119222183728.94562),\n",
       " ('is_Typ_XPos', -35912264064.179337),\n",
       " ('is_Typ_xQt0', 119222183728.46742),\n",
       " ('is_Typ_XQtl', 119222183728.56023),\n",
       " ('is_Typ_xQtX', 119222183728.37636),\n",
       " ('is_Typ_xYq0', 119222183728.38239),\n",
       " ('is_Typ_XYqt', 119222183728.5961),\n",
       " ('is_Typ_xYqX', 119222183728.36879),\n",
       " ('is_Typ_ZIm0', 119222183728.50751),\n",
       " ('is_Typ_ZImX', 119222183728.23318),\n",
       " ('is_Typ_ZQt0', 119222183728.77869),\n",
       " ('is_Typ_ZQtX', 119222183728.67239),\n",
       " ('is_Typ_ZYq0', 119222183728.82394),\n",
       " ('is_Typ_ZYqX', 119222183728.70251),\n",
       " ('is_Domain_N', -0.59521484375),\n",
       " ('is_Domain_Q', -0.263916015625),\n",
       " ('is_Domain_D', -0.2421875)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create X and y\n",
    "feature_cols = [\"depth\", \"is_Kind_VC\", \"is_Kind_WP\", \"is_Kind_NC\", \"is_Rela_ReVo\", \"is_Rela_Coor\", \"is_Rela_Attr\", \"is_Rela_Cmpl\", \"is_Rela_Resu\", \"is_Rela_Adju\", \"is_Rela_Objc\", \"is_Rela_RgRc\", \"is_Rela_Subj\", \"is_Rela_PrAd\", \"is_Rela_PreC\", \"is_Rela_Spec\", \"is_Typ_AjCl\", \"is_Typ_CPen\", \"is_Typ_Defc\", \"is_Typ_Ellp\", \"is_Typ_InfA\", \"is_Typ_InfC\", \"is_Typ_MSyn\", \"is_Typ_NmCl\", \"is_Typ_Ptcp\", \"is_Typ_Reop\", \"is_Typ_Unkn\", \"is_Typ_Voct\", \"is_Typ_Way0\", \"is_Typ_WayX\", \"is_Typ_WIm0\", \"is_Typ_WImX\", \"is_Typ_WQt0\", \"is_Typ_WQtX\", \"is_Typ_WxI0\", \"is_Typ_WXIm\", \"is_Typ_WxIX\", \"is_Typ_WxQ0\", \"is_Typ_WXQt\", \"is_Typ_WxQX\", \"is_Typ_WxY0\", \"is_Typ_WXYq\", \"is_Typ_WxYX\", \"is_Typ_WYq0\", \"is_Typ_WYqX\", \"is_Typ_xIm0\", \"is_Typ_XImp\", \"is_Typ_xImX\", \"is_Typ_XPos\", \"is_Typ_xQt0\", \"is_Typ_XQtl\", \"is_Typ_xQtX\", \"is_Typ_xYq0\", \"is_Typ_XYqt\", \"is_Typ_xYqX\", \"is_Typ_ZIm0\", \"is_Typ_ZImX\", \"is_Typ_ZQt0\", \"is_Typ_ZQtX\", \"is_Typ_ZYq0\", \"is_Typ_ZYqX\", \"is_Domain_N\", \"is_Domain_Q\", \"is_Domain_D\"]\n",
    "# feature_cols = [\"depth\", \"is_Kind_VC\", \"is_Kind_WP\", \"is_Kind_NC\", \"is_Domain_N\", \"is_Domain_Q\", \"is_Domain_D\"]\n",
    "\n",
    "X = pdd[feature_cols]\n",
    "y = pdd.is_Poetry\n",
    "\n",
    "# follow the usual sklearn pattern: import, instantiate, fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, y)\n",
    "\n",
    "# print intercept and coefficients\n",
    "print(lm.intercept_)\n",
    "list(zip(feature_cols, lm.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
